|||
|---|---|
|ДИСЦИПЛИНА|Прикладная математика|
|ИНСТИТУТ|ИПТИП|
|КАФЕДРА|Индустриального программирования|
|ВИД УЧЕБНОГО МАТЕРИАЛА|Методические указания по дисциплине|
|ПРЕПОДАВАТЕЛЬ|Астафьев Рустам Уралович|
|СЕМЕСТР|1 семестр, 2025/2026 уч. год|

Ссылка на материал: <br>
https://github.com/astafiev-rustam/applied-mathematics/tree/lecture-1-5

# Лекция №5: Нейросетевые модели

## Введение в продвинутые нейросетевые модели

Преодоление ограничений простого персептрона привело к созданию глубоких нейронных сетей, обладающих множеством скрытых слоев. Глубокие сети способны выявлять иерархические представления в данных. На нижних уровнях сеть учится распознавать простые признаки, такие как края и углы на изображении. На последующих слоях эти признаки комбинируются в более сложные, например, в очертания носов и глаз. На верхних уровнях сеть оперирует абстрактными понятиями, такими как "лицо" или "кошка". Для эффективного обучения таких сложных архитектур были разработаны specialized средства и модели.

## Сверточные нейронные сети

Сверточные нейронные сети стали прорывом в области компьютерного зрения. Их архитектура явным образом учитывает пространственную структуру данных, таких как изображения. Вместо полносвязных слоев, где каждый нейрон связан со всеми входами, СНС используют сверточные слои. Нейроны в таких слоях связаны только с небольшой локальной областью предыдущего слоя, что резко сокращает количество параметров. Ключевыми компонентами СНС являются свертка, которая применяет набор фильтров для выделения признаков, и операция подвыборки, которая уменьшает размерность представления, повышая инвариантность к малым смещениям и искажениям.

## Рекуррентные нейронные сети

Рекуррентные нейронные сети предназначены для работы с последовательностями данных, где важен контекст и порядок элементов. В отличие от feed-forward сетей, где информация течет строго от входа к выходу, РНС имеют обратные связи. Это позволяет им сохранять внутреннее состояние, своего рода "память" о предыдущих элементах последовательности. Каждый нейрон в рекуррентном слое получает на вход не только текущий элемент последовательности, но и свое собственное состояние с предыдущего шага. Эта архитектура делает РНС идеальным инструментом для таких задач, как машинный перевод, анализ тональности текста и распознавание речи.

## Методы регуляризации и оптимизации

Обучение глубоких сетей сопряжено с риском переобучения, когда сеть запоминает обучающие примеры вместо того, чтобы выучивать общие закономерности. Для борьбы с этим применяются методы регуляризации. Dropout случайным образом "отключает" часть нейронов во время обучения, что предотвращает ко-адаптацию нейронов и заставляет сеть быть более robust. Другим critical методом является использование различных алгоритмов оптимизации, таких как Adam или RMSprop. Эти алгоритмы адативно настраивают скорость обучения для каждого параметра сети, что ускоряет сходимость и помогает избежать застревания в локальных минимумах.

## Области применения сложных моделей

Продвинутые нейросетевые модели нашли применение в создании интеллектуальных систем, трансформирующих целые индустрии. СНС лежат в основе систем автономного вождения, обеспечивая распознавание пешеходов, знаков и других транспортных средств. РНС и их более совершенные версии, такие как сети с долгой краткосрочной памятью, используются в голосовых помощниках для понимания естественного языка. Генеративно-состязательные сети применяются для создания фотореалистичных изображений и синтеза речи. Эти примеры иллюстрируют, как специализированные архитектуры позволяют решать задачи, ранее считавшиеся недоступными для машин.

# Примеры и реализация
Рассмотрим примеры по теме лекционного занятия:

[Пример 1](https://habr.com/ru/articles/506042/)

[Пример 2](https://skillbox.ru/media/design/ii_rus/)

[Пример 3](https://habr.com/ru/companies/x-com/articles/852456/)